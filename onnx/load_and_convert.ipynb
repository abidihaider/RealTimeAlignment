{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30feb9b8-002b-4886-8810-6f9e6b44bc06",
   "metadata": {},
   "source": [
    "# Load an MLP model and convert it to ONNX file\n",
    "Please take the following steps before running this notebook\n",
    "1. clone the repo by running `git clone https://github.com/abidihaider/RealTimeAlignment.git`\n",
    "2. check to the develop branch of the repo\n",
    "3. run `python setup.py develop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c741f2bf-2fbf-4dcd-9158-5058c4430285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46aaf21-52c1-45f8-a95c-2a8b526d7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7615b622-c4ad-424d-b7cc-c59ef1496ce3",
   "metadata": {},
   "source": [
    "## Load model configuration and use it to initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a345d4f2-5c07-4b78-b596-dc14db188ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'checkpointing': {'checkpoint_path': '/home/yhuang2/PROJs/RealTimeAlignment/train/mlp_v2/checkpoints', 'resume': True, 'save_frequency': 20}, 'data': {'mode': 'raw', 'num_particles': 50, 'rounded': False}, 'model': {'embedding_features': [128, 128], 'in_features': 6, 'out_features': 27, 'rezero': True, 'norm': None, 'activ': {'name': 'leakyrelu', 'negative_slope': 0.1}, 'subset_config': [[6, 128, 128, 128, 128], [6, 128, 128, 128, 128], [6, 128, 128, 128, 128]]}, 'train': {'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 200, 'num_warmup_epochs': 50, 'sched_gamma': 0.95, 'sched_steps': 20}}\n"
     ]
    }
   ],
   "source": [
    "with open('checkpoints/config.yaml', 'r', encoding='UTF-8') as handle:\n",
    "    config = yaml.safe_load(handle)\n",
    "print(config)\n",
    "model = MLP(**config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc43f06-586a-448b-9fec-1e8b0033dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embed): Sequential(\n",
       "    (0): Identity()\n",
       "    (1): Linear(in_features=6, out_features=128, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Identity()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (solvers): ModuleList(\n",
       "    (0-2): 3 x SubsetSolver(\n",
       "      (model): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): Linear(in_features=768, out_features=128, bias=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "        (3): ResLinear(\n",
       "          (norm_layer): Identity()\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activ): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (4): ResLinear(\n",
       "          (norm_layer): Identity()\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activ): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (5): ResLinear(\n",
       "          (norm_layer): Identity()\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activ): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=128, out_features=27, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = 'checkpoints/ckpt_last.path'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "model_state_dict = ckpt['model']\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bb4ea-4615-40fb-858d-a6e298431117",
   "metadata": {},
   "source": [
    "## Convert it to an ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e637fbf-153b-416d-aaf8-c902ff2ef655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been exported to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "# Create dummy input with the correct shape\n",
    "in_features = config['model']['in_features']\n",
    "num_particles = config['data']['num_particles']\n",
    "dummy_input = torch.randn(1, num_particles, in_features)\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,                      # model being run\n",
    "    dummy_input,                # model input (or a tuple for multiple inputs)\n",
    "    \"mlp.onnx\",                 # where to save the model (filename)\n",
    "    export_params=True,         # store the trained weights inside the model\n",
    "    opset_version=11,           # the ONNX version to export to (11 is widely supported)\n",
    "    do_constant_folding=True,   # optimize constants\n",
    "    input_names=['input'],      # input name (can be arbitrary)\n",
    "    output_names=['output'],    # output name\n",
    "    dynamic_axes={              # support dynamic batch size\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Model has been exported to ONNX format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c762bd-06e7-4188-ba04-48a4c642e03a",
   "metadata": {},
   "source": [
    "## Load the ONNX model and check its validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36edef95-556e-4f9d-9c94-2e36ca624235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "onnx_path = 'mlp.onnx' \n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(\"ONNX model is valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d91ae2-06c4-4bfb-8ce7-1731a34e6a01",
   "metadata": {},
   "source": [
    "## Test the ONNX model with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219189ea-5b9e-41d6-848f-852c03f358b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model tested successfully!\n"
     ]
    }
   ],
   "source": [
    "ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "\n",
    "# Numpy dummy input\n",
    "input_data = dummy_input.numpy()\n",
    "\n",
    "# Run the ONNX model\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n",
    "ort_outputs = ort_session.run(None, ort_inputs)\n",
    "print(\"ONNX model tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636a453-35a0-42a2-aadf-c17370a78892",
   "metadata": {},
   "source": [
    "## Load toy detector data and compare the results of PyTorch model and ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba89d44-18f3-46f6-a5bc-f911ec35aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtal.datasets.dataset import ROMDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec1bb7-19e6-4ea1-b17b-ac428f05fa5e",
   "metadata": {},
   "source": [
    "load some example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3095a7-a39c-45d9-91ca-b229e0cd692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/rom_det-3_part-200_cont-and-rounded_excerpt/'\n",
    "dataset  = ROMDataset(data_root, split='train', num_particles=50)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ec3c6-8682-4df1-b095-affee016f63b",
   "metadata": {},
   "source": [
    "get one batch (contains 4 events since we set the `batch_size=4` in the data loader) and run PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e0231d-a9ae-4f7b-ac85-111ce227d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = next(iter(dataloader))\n",
    "# readout generated by the misaligned detectors\n",
    "# \"_cont\" here means the coordinates are continuous without any rounding.\n",
    "readout = event[f'readout_curr_cont'].to(device)\n",
    "# readout: (batch_size, num_detectors, num_particles, 2)\n",
    "#        ->(batch_size, num_particles, num_detectors, 2)\n",
    "#        ->(batch_size, num_particles, num_detectors x 2)\n",
    "readout = torch.transpose(readout, 1, 2).flatten(-2, -1)\n",
    "torch_outputs = model(readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fae8cf-d6e1-4c67-bd9e-5ddc4b1c8252",
   "metadata": {},
   "source": [
    "run the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b196c420-7afc-4028-b8bb-251b63749971",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: readout.numpy()}\n",
    "ort_outputs = ort_session.run(None, ort_inputs)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5f584-f344-447d-936e-e383563cb4ff",
   "metadata": {},
   "source": [
    "Compare PyTorch and ONNX outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5156a185-a08d-4c5f-9369-eefef518ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max difference between PyTorch and ONNX outputs: 0.000000\n"
     ]
    }
   ],
   "source": [
    "difference = np.abs(torch_outputs.detach().numpy() - ort_outputs)\n",
    "max_diff = np.max(difference)\n",
    "print(f\"Max difference between PyTorch and ONNX outputs: {max_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e892a7-55b7-4005-a7ca-d08527d217ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22556a9-f882-4219-a2d0-563562b34d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtdc",
   "language": "python",
   "name": "rtdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
