{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f30fa-04f5-409f-9920-a5a3216a1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b932558-cf02-4d6a-9c76-c6b7ab5c5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_folder = Path('/home/yhuang2/PROJs/RealTimeAlignment/notebooks/frontier_results/')\n",
    "plot_folder = proj_folder/'plots'\n",
    "df = pd.read_csv(proj_folder/'performance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45c418-9485-47c4-8e03-1510790132e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['num_features', 'num_subset_solvers', 'subset_size', 'subset_solver_depth']\n",
    "\n",
    "model_str = []\n",
    "for _, row in df.iterrows():\n",
    "    tokens = []\n",
    "    for param in parameters:\n",
    "        tokens.append(f'{param}-{row[param]}')\n",
    "    model_str.append('|'.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84514189-67e9-40f2-ae4a-4d98770bea27",
   "metadata": {},
   "source": [
    "## studies\n",
    "1. performance as function of model_size\n",
    "2. fix _one_ parameter in (\"num_features\", \"num_subset_solvers\", \"subset_size\", \"subset_solver_depth\"), average over all other features to show the influence of this one features on \"diff_pc\"\n",
    "3. fix _two_ parameters and do the same study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55c543-d8de-48af-a0b6-7f4efd7f96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'diff'\n",
    "if metric  == 'diff':\n",
    "    metric_str = 'MSE'\n",
    "else:\n",
    "    metric_str = 'Residual'\n",
    "\n",
    "df_cont = df[df.rounded==False]\n",
    "\n",
    "for parameter in parameters:\n",
    "    fig = go.Figure()\n",
    "    trace = go.Scatter(\n",
    "        x=df_cont['model_size_mb'],\n",
    "        y=df_cont[f'valid_{metric}_pc'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, \n",
    "                    color=df_cont[parameter],\n",
    "                    colorscale='Viridis',),\n",
    "        text=model_str, # What shows up on hover\n",
    "        hoverinfo='text', # Show only the text, not (x,y) by default\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "    fig.update_layout(\n",
    "        width=600,\n",
    "        height=500,\n",
    "        title=f'{metric_str} as function of model_size (color={parameter})',\n",
    "        xaxis_title='model size (MB)',\n",
    "        yaxis_title=f'{metric_str}'\n",
    "    )\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3effdc-0a17-4fbd-8437-fbbdca546e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df[df.rounded==False]\n",
    "\n",
    "for pair in combinations(parameters, 2):\n",
    "    fig = go.Figure()\n",
    "    trace = go.Scatter(\n",
    "        x=df_cont['model_size_mb'],\n",
    "        y=df_cont[f'valid_{metric}_pc'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, \n",
    "                    color=df_cont[pair[0]] * df_cont[pair[1]],\n",
    "                    colorscale='Viridis',),\n",
    "        text=model_str, # What shows up on hover\n",
    "        hoverinfo='text', # Show only the text, not (x,y) by default\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "    fig.update_layout(\n",
    "        width=750,\n",
    "        height=500,\n",
    "        title=f'{metric_str} as function of model_size<br>color={pair}',\n",
    "        xaxis_title='model size (MB)',\n",
    "        yaxis_title=f'{metric_str}'\n",
    "    )\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652a0e0-fdd6-4ccf-8365-ed872ea7ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df[df.rounded==False]\n",
    "\n",
    "for pair in combinations(parameters, 3):\n",
    "    fig = go.Figure()\n",
    "    trace = go.Scatter(\n",
    "        x=df_cont['model_size_mb'],\n",
    "        y=df_cont[f'valid_{metric}_pc'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, \n",
    "                    color=df_cont[pair[0]] * df_cont[pair[1]] * df_cont[pair[2]],\n",
    "                    colorscale='Viridis',),\n",
    "        text=model_str, # What shows up on hover\n",
    "        hoverinfo='text', # Show only the text, not (x,y) by default\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "    fig.update_layout(\n",
    "        width=750,\n",
    "        height=500,\n",
    "        title=f'{metric_str} as function of model_size<br>color={pair}',\n",
    "        xaxis_title='model size (MB)',\n",
    "        yaxis_title=f'{metric_str}'\n",
    "    )\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dcae0-7d96-4317-9d59-d527c68009af",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['num_features', 'num_subset_solvers', 'subset_size', 'subset_solver_depth']\n",
    "\n",
    "metric = 'diff'\n",
    "# metric = 'res'\n",
    "if metric  == 'diff':\n",
    "    zmin = df[f'valid_{metric}_pc'].min()\n",
    "    zmax = df[f'valid_{metric}_pc'].max()\n",
    "    cbar_title = 'MSE'\n",
    "else:\n",
    "    zmin = df[f'valid_{metric}_pc'].min()\n",
    "    zmax = df[f'valid_{metric}_pc'].max()\n",
    "    cbar_title = 'Residual'\n",
    "\n",
    "for parameter in parameters:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for rounded, color in zip([True, False], ['lightskyblue', 'lightcoral']):\n",
    "        df_temp = df[df.rounded == rounded].groupby(by=parameter).mean()\n",
    "        df_temp[parameter] = df_temp.index.astype(str)\n",
    "\n",
    "        trace = go.Bar(x=df_temp[parameter],\n",
    "                       y=df_temp[f'valid_{metric}_pc'],\n",
    "                       name=f'rounded: {rounded}',\n",
    "                       marker_color=color)\n",
    "        fig.add_trace(trace)\n",
    "\n",
    "    title = f'Residual as function of {parameter}'\n",
    "    fig.update_layout(\n",
    "        width=750,\n",
    "        height=500,\n",
    "        barmode='group',\n",
    "        font=dict(family='Lucida Console',\n",
    "                  size=13,),\n",
    "                  # color='black')\n",
    "        title=title,\n",
    "        xaxis=dict(title=parameter,),\n",
    "        yaxis=dict(title='validation Residual',\n",
    "                   range=[zmin, zmax]),\n",
    "        legend=dict(x=.98,\n",
    "                    y=.98,\n",
    "                    xanchor='right',\n",
    "                    yanchor='top',\n",
    "                    bgcolor='rgba(255,255,255,0.75)',)\n",
    "                    # bordercolor='black',\n",
    "                    # borderwidth=1)\n",
    "    )\n",
    "    fig.show()\n",
    "    fig.write_image(plot_folder/f'residual_vs_{parameter}.png', scale=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4868fa-24a6-45aa-b0f4-1a4283a1e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [True, False]\n",
    "colors = ['lightskyblue', 'lightcoral']\n",
    "rounded[1]\n",
    "\n",
    "metric = 'res'\n",
    "# metric = 'diff'\n",
    "if metric  == 'diff':\n",
    "    zmin = df[f'valid_{metric}_pc'].min()\n",
    "    zmax = df[f'valid_{metric}_pc'].max()\n",
    "    cbar_title = 'MSE'\n",
    "else:\n",
    "    zmin = df[f'valid_{metric}_pc'].min()\n",
    "    zmax = df[f'valid_{metric}_pc'].max()\n",
    "    cbar_title = 'Residual'\n",
    "\n",
    "for pair in combinations(parameters, 2):\n",
    "    print(pair)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        subplot_titles=(f\"rounded = {rounded[0]}\", \n",
    "                                        f\"rounded = {rounded[1]}\"))\n",
    "    \n",
    "    for i, (rd, color) in enumerate(zip(rounded, colors), start=1):\n",
    "        df_temp = df[df.rounded == rd].groupby(by=list(pair))[f'valid_{metric}_pc'].mean().reset_index()\n",
    "        df_temp = pd.pivot_table(df_temp, index=pair[0], columns=pair[1])\n",
    "        \n",
    "        y_ticklabels = list(map(str, list(df_temp.index)))\n",
    "        x_ticklabels = [str(col[1]) for col in df_temp.columns]\n",
    "        \n",
    "        # Add first heatmap without colorbar\n",
    "        trace = go.Heatmap(z=df_temp.values, \n",
    "                           colorscale='RdBu_r', \n",
    "                           showscale=True, \n",
    "                           zmin=zmin,\n",
    "                           zmax=zmax,\n",
    "                           x=x_ticklabels,  # x-axis tick labels\n",
    "                           y=y_ticklabels,  # y-axis tick labels\n",
    "                           text=df_temp.values,  # This will be used as labels\n",
    "                           texttemplate=\"%{text:.5f}\",  # Show text directly in each cell\n",
    "                           textfont={\"size\":11, \"color\":\"black\"},  # Customize font color/size\n",
    "                           colorbar=dict(title=f\"{cbar_title}\"))\n",
    "        fig.add_trace(trace, row=1, col=i)\n",
    "        fig.update_xaxes(title_text=pair[1], row=1, col=i)\n",
    "        fig.update_yaxes(title_text=pair[0], row=1, col=i)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{cbar_title} {pair[0]} vs {pair[1]}\",\n",
    "        height=500,\n",
    "        width=900,\n",
    "    )\n",
    "    fig.show()\n",
    "    fig.write_image(plot_folder/f'{cbar_title}-{pair[0]}-vs-{pair[1]}.png', scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1edd9-7417-4853-811e-32a27ff482a3",
   "metadata": {},
   "source": [
    "## Get winners models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1b2f9-13fa-4d45-9ebc-483ef532770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 10\n",
    "for rounded in [False, True]:\n",
    "    diff_winners = df[df.rounded == rounded].sort_values(f'valid_diff_pc')[ : top]\n",
    "    res_winners = df[df.rounded == rounded].sort_values(f'valid_res_pc')[ : top]\n",
    "    \n",
    "    winner = pd.merge(diff_winners, res_winners, on=parameters, how='inner')\n",
    "    \n",
    "    winner['valid_diff_pc'] = (winner['valid_diff_pc_x'] + winner['valid_diff_pc_y']) / 2\n",
    "    winner['valid_res_pc'] = (winner['valid_res_pc_x'] + winner['valid_res_pc_y']) / 2\n",
    "    \n",
    "    print(winner[parameters + ['valid_diff_pc', 'valid_res_pc', 'valid_res_sc_y']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtdc",
   "language": "python",
   "name": "rtdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
